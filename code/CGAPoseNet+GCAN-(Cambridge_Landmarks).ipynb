{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNmZCKUmcWM-"
      },
      "source": [
        "#Defining CGAPoseNet+GCAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQ1oXFXlt0-G"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Reshape, Flatten, GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "#Loading GoogLeNet with ImageNet weights\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "# summarize the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKY-c5165sA3"
      },
      "outputs": [],
      "source": [
        "!pip install tfga\n",
        "from tfga import GeometricAlgebra\n",
        "from tfga.layers import TensorToGeometric, GeometricProductConv1D, GeometricToTensor, GeometricSandwichProductDense, GeometricProductDense\n",
        "ga = GeometricAlgebra(metric=[1, 1, 1, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eap2YxT5KNPv"
      },
      "outputs": [],
      "source": [
        "#modifying the last layer\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "idx = ga.get_kind_blade_indices(\"even\")\n",
        "model = InceptionV3(classifier_activation = None, weights = \"imagenet\", input_tensor=Input(shape=(224, 224, 3)))\n",
        "\n",
        "x2 = Dropout(0.3)(model.layers[-2].output)\n",
        "x2 = Reshape((-1, 8))(x2)\n",
        "x2 = TensorToGeometric(ga, blade_indices=idx)(x2)\n",
        "x2 = GeometricSandwichProductDense(\n",
        "        ga, units=128, activation = \"relu\",\n",
        "        blade_indices_kernel=idx,\n",
        "        blade_indices_bias=idx)(x2)\n",
        "x2 = GeometricSandwichProductDense(\n",
        "        ga, units=64, activation = \"relu\",\n",
        "        blade_indices_kernel=idx,\n",
        "        blade_indices_bias=idx)(x2)\n",
        "outputs2 = GeometricSandwichProductDense(\n",
        "        ga, units=1, activation = \"tanh\",\n",
        "        blade_indices_kernel=idx,\n",
        "        blade_indices_bias=idx)(x2)\n",
        "#x2 = GeometricToTensor(ga, blade_indices=idx)(x2)\n",
        "#outputs2 = Flatten()(x2)\n",
        "\n",
        "Model1 = tf.keras.Model(inputs=model.input, outputs=outputs2)\n",
        "Model1.summary()\n",
        "CGAPoseNet = Model1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wCNz8twcZ9D"
      },
      "source": [
        "# Converting Camera Poses into Motors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_59LfNqDLTD"
      },
      "outputs": [],
      "source": [
        "FOLDER = \"OldHospital\" #Change the name to change the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlI5XNDYcbFj"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZG1xqTUIS7i"
      },
      "outputs": [],
      "source": [
        "!pip install clifford"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAzn_xo4omZv"
      },
      "outputs": [],
      "source": [
        "from clifford.g3c import *\n",
        "from math import sqrt\n",
        "import numpy as np\n",
        "\n",
        "lambda_coeff = 200\n",
        "\n",
        "#functions to convert quaternions coefficients into to GA rotors\n",
        "def q2S(*args):\n",
        "    '''\n",
        "    convert tuple of quaternion coefficients to a spinor'''\n",
        "    q = args\n",
        "    return q[0] + q[1]*e13 +q[2]*e23 + q[3]*e12\n",
        "\n",
        "#From Euclidean to 1D Up CGA.\n",
        "#function implementing Eq. 6 (convert a vector in Euclidean space into a rotor\n",
        "#in spherical space)\n",
        "def translation_rotor(a, L = lambda_coeff):\n",
        "    Ta = (L + a*e4)/(sqrt(L**2 + a**2))\n",
        "    return Ta\n",
        "\n",
        "#From Euclidean to 1D Up CGA. function implementing the Eq. 10 (X = f(x))\n",
        "def up1D(x, L = lambda_coeff):\n",
        "    Y = (2*L / (L**2 + x**2))*x + ((L**2-x**2)/(L**2 + x**2))*e4\n",
        "    return Y\n",
        "\n",
        "#From 1D Up CGA to Euclidean. function implementing the inverse of Eq. 10 (x = f^{-1}(X))\n",
        "'''\n",
        "def down1D(Y, x, L = lambda_coeff):\n",
        "    alpha = (2*L/(L**2 + x**2))\n",
        "    beta  =  (L**2 - x**2)/(L**2 + x**2)\n",
        "    x = (Y - beta*e4)/alpha\n",
        "\n",
        "    return x\n",
        "'''\n",
        "\n",
        "def down1D(Y, L = lambda_coeff):\n",
        "    x = (L/(1 + Y*e4))*((Y|e1)*e1 + (Y|e2)*e2 + (Y|e3)*e3)\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLTMEMV5h2Fl"
      },
      "source": [
        "## Loading Train-Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9z1OIujeO4y"
      },
      "outputs": [],
      "source": [
        "#reads the dataset labels and converts them into motors (Train set)\n",
        "\n",
        "list_of_lines = open(\"/content/drive/MyDrive/\"+ FOLDER + \"/dataset_train.txt\").readlines()\n",
        "newfile = open(\"/content/drive/MyDrive/\"+ FOLDER + \"/new_dataset_train.txt\", \"w\")\n",
        "\n",
        "position_train = []\n",
        "\n",
        "for i in range(0,3):\n",
        "    newfile.write(list_of_lines[i])\n",
        "    newfile.write(\"\\n\")\n",
        "\n",
        "for i in range(3, len(list_of_lines)):\n",
        "\n",
        "    a = []\n",
        "    a = list_of_lines[i].split()\n",
        "\n",
        "    position_train = np.append(position_train, [float(a[1]), float(a[2]), float(a[3])])\n",
        "\n",
        "    Ta = translation_rotor(float(a[1])*e1 + float(a[2])*e2 + float(a[3])*e3)\n",
        "    R = q2S(float(a[4]), float(a[5]), float(a[6]), float(a[7]))\n",
        "\n",
        "    M = Ta*R\n",
        "\n",
        "    a[1] = M[0]\n",
        "    a[2] = M[6]\n",
        "    a[3] = M[7]\n",
        "    a[4] = M[8]\n",
        "    a[5] = M[10]\n",
        "    a[6] = M[11]\n",
        "    a[7] = M[13]\n",
        "    a.append(M[26])\n",
        "\n",
        "    b = \" \".join(map(str, a))\n",
        "    list_of_lines[i] = b\n",
        "    newfile.write(list_of_lines[i])\n",
        "    newfile.write(\"\\n\")\n",
        "\n",
        "print(i)\n",
        "position_train = np.reshape(position_train, (-1, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gQsrO2tp_Fz"
      },
      "outputs": [],
      "source": [
        "list_train = open(\"/content/drive/MyDrive/\"+ FOLDER + \"/new_dataset_train.txt\").readlines() # no need for closing, python will do it for you\n",
        "len(list_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82Y1NTRSgKyW"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import csv\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "x_train = []\n",
        "\n",
        "#reads the dataset frames, reshapes them and normalizes them  (Train Set)\n",
        "\n",
        "list_train = open(\"/content/drive/MyDrive/\"+ FOLDER + \"/new_dataset_train.txt\").readlines() # no need for closing, python will do it for you\n",
        "print(len(list_train))\n",
        "\n",
        "\n",
        "dir = \"/content/drive/MyDrive/\"+ FOLDER + \"/\"\n",
        "\n",
        "with open(dir + 'TRAIN.csv', \"w\") as csv_file:\n",
        "    fieldnames = ['filename', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']\n",
        "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
        "    writer.writeheader()\n",
        "\n",
        "    for i in range(6, len(list_train)):\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print(i)\n",
        "\n",
        "        a = list_train[i].split()\n",
        "\n",
        "        #img = cv2.imread(\"/content/drive/MyDrive/\"+ FOLDER + \"/\" + a[0])\n",
        "\n",
        "        #resized = cv2.resize(img, (224, 224))\n",
        "        #normalized = cv2.normalize(resized, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
        "\n",
        "        #x_train = np.append(x_train, normalized)\n",
        "\n",
        "        d = {'filename': a[0],\n",
        "                     'a':a[1],\n",
        "                     'b':a[2],\n",
        "                     'c':a[3],\n",
        "                     'd':a[4],\n",
        "                     'e':a[5],\n",
        "                     'f':a[6],\n",
        "                     'g':a[7],\n",
        "                     'h':a[8]}\n",
        "        writer.writerow(d)\n",
        "\n",
        "\n",
        "# Output img with window name as 'image'\n",
        "#cv2_imshow(img)\n",
        "#cv2_imshow(resized)\n",
        "\n",
        "#np.save(\"x_train.npy\", x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7i6RyhLeN6H"
      },
      "outputs": [],
      "source": [
        "#reads the dataset labels and converts them into motors (Test Set)\n",
        "\n",
        "list_of_lines = open(\"/content/drive/MyDrive/\"+ FOLDER + \"/dataset_test.txt\").readlines() # no need for closing, python will do it for you\n",
        "newfile = open(\"/content/drive/MyDrive/\"+ FOLDER + \"/new_dataset_test.txt\", \"w\")\n",
        "\n",
        "position_test = []\n",
        "for i in range(0,3):\n",
        "    newfile.write(list_of_lines[i])\n",
        "    newfile.write(\"\\n\")\n",
        "\n",
        "for i in range(3, len(list_of_lines)):\n",
        "\n",
        "    a = []\n",
        "    a = list_of_lines[i].split()\n",
        "\n",
        "    #print(a)\n",
        "\n",
        "    position_test = np.append(position_test, [float(a[1]), float(a[2]), float(a[3])])\n",
        "\n",
        "\n",
        "    Ta = translation_rotor(float(a[1])*e1 + float(a[2])*e2 + float(a[3])*e3)\n",
        "    R = q2S(float(a[4]), float(a[5]), float(a[6]), float(a[7]))\n",
        "\n",
        "    M = Ta*R\n",
        "\n",
        "    a[1] = M[0]\n",
        "    a[2] = M[6]\n",
        "    a[3] = M[7]\n",
        "    a[4] = M[8]\n",
        "    a[5] = M[10]\n",
        "    a[6] = M[11]\n",
        "    a[7] = M[13]\n",
        "    a.append(M[26])\n",
        "\n",
        "    #print(a)\n",
        "\n",
        "    b = \" \".join(map(str, a))\n",
        "    list_of_lines[i] = b\n",
        "    newfile.write(list_of_lines[i])\n",
        "    newfile.write(\"\\n\")\n",
        "\n",
        "    if i == 3:\n",
        "        print(a)\n",
        "        print(list_of_lines[i])\n",
        "\n",
        "position_test = np.reshape(position_test, (-1, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cy9eNCuDh2zz"
      },
      "outputs": [],
      "source": [
        "y_test = []\n",
        "\n",
        "#reads the dataset frames, reshapes them and normalizes them  (Train Set)\n",
        "\n",
        "list_test = open(\"/content/drive/MyDrive/\"+ FOLDER + \"/new_dataset_test.txt\").readlines()\n",
        "\n",
        "with open(dir + 'TEST.csv', \"w\") as csv_file:\n",
        "    fieldnames = ['filename', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']\n",
        "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
        "    writer.writeheader()\n",
        "\n",
        "    for i in range(6, len(list_test)):\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print(i)\n",
        "\n",
        "        a = list_test[i].split()\n",
        "\n",
        "        #img = cv2.imread(\"/content/drive/MyDrive/\"+ FOLDER + \"/\" + a[0])\n",
        "\n",
        "        #resized = cv2.resize(img, (224, 224))\n",
        "        #normalized = cv2.normalize(resized, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
        "\n",
        "        #x_train = np.append(x_train, normalized)\n",
        "\n",
        "        y_test.append(float(a[1]))\n",
        "        y_test.append(float(a[2]))\n",
        "        y_test.append(float(a[3]))\n",
        "        y_test.append(float(a[4]))\n",
        "        y_test.append(float(a[5]))\n",
        "        y_test.append(float(a[6]))\n",
        "        y_test.append(float(a[7]))\n",
        "        y_test.append(float(a[8]))\n",
        "\n",
        "\n",
        "\n",
        "        d = {'filename': a[0],\n",
        "                     'a':a[1],\n",
        "                     'b':a[2],\n",
        "                     'c':a[3],\n",
        "                     'd':a[4],\n",
        "                     'e':a[5],\n",
        "                     'f':a[6],\n",
        "                     'g':a[7],\n",
        "                     'h':a[8]}\n",
        "        writer.writerow(d)\n",
        "\n",
        "\n",
        "y_test = np.reshape(y_test, (-1, 8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSZ-aPFjsRfj"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "df_train =pd.read_csv(dir + '/TRAIN.csv')\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        rescale=1./255)\n",
        "\n",
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        rescale=1./255)\n",
        "\n",
        "#df = pd.read_csv(dir + 'train_df.csv', delimiter=' ', header=None, names=['filename', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'])\n",
        "columns = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']\n",
        "train_generator = train_datagen.flow_from_dataframe(dataframe=df_train, directory=dir,\n",
        "                                              x_col=\"filename\", y_col=columns, has_ext=True,\n",
        "                                              class_mode=\"raw\", target_size=(224, 224),\n",
        "                                              shuffle = True,\n",
        "                                              sort = False,\n",
        "                                              batch_size=64)\n",
        "\n",
        "df_test =pd.read_csv(dir + '/TEST.csv')\n",
        "test_generator = test_datagen.flow_from_dataframe(dataframe=df_test, directory=dir,\n",
        "                                              x_col=\"filename\", y_col=columns, has_ext=True,\n",
        "                                              class_mode=\"raw\", target_size=(224, 224),\n",
        "                                              shuffle = False,\n",
        "                                              sort = False,\n",
        "                                              batch_size=64)\n",
        "\n",
        "\n",
        "position_test = np.reshape(position_test, (-1, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7o1rSZyrsmQ"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYcsLhdc1KMg"
      },
      "outputs": [],
      "source": [
        "def custom_loss(y_true, y_pred):\n",
        "\n",
        "    y_true = TensorToGeometric(ga, blade_indices=idx)(y_true)\n",
        "    y_true = tf.expand_dims(y_true, axis = 1)\n",
        "\n",
        "    prod1 = ga.geom_prod(y_true, ga.reversion(y_pred))[...,0]\n",
        "    return tf.reduce_mean(tf.math.square(prod1 - 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXH65O9FVBtf"
      },
      "outputs": [],
      "source": [
        "#defining hyperparameters\n",
        "\n",
        "nb_epoch = 100\n",
        "batch_size = 64\n",
        "\n",
        "initial_learning_rate = 1e-4\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate,\n",
        "    decay_steps=100,\n",
        "    decay_rate=0.98,\n",
        "    staircase=True)\n",
        "\n",
        "#compiling the model\n",
        "CGAPoseNet.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
        "                 loss=custom_loss, run_eagerly=True)\n",
        "\n",
        "es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=12, restore_best_weights = True)\n",
        "\n",
        "#training\n",
        "model_train = CGAPoseNet.fit(train_generator,\n",
        "                            validation_data=test_generator,\n",
        "                            epochs=nb_epoch,\n",
        "                            verbose=1,\n",
        "                            shuffle=True,\n",
        "                            callbacks = es_callback,\n",
        "                            batch_size=batch_size)\n",
        "\n",
        "#plotting losses\n",
        "loss = model_train.history['loss']\n",
        "val_loss = model_train.history['val_loss']\n",
        "epochs = range(0,np.size(loss))\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'b-', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r-', label='Validation loss')\n",
        "plt.title('Training loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "C__F4LXnPjQX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "by0gFJhDS3TL"
      },
      "outputs": [],
      "source": [
        "#storing losses\n",
        "np.save(\"train_loss.npy\", loss)\n",
        "np.save(\"val_loss.npy\", val_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z245LMHDTFn-"
      },
      "outputs": [],
      "source": [
        "#saving weights\n",
        "CGAPoseNet.save('weights.h5')\n",
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSwIlA-Rv96v"
      },
      "source": [
        "[link text](https:// [link text](https://))# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCX25ZCxq8IY"
      },
      "outputs": [],
      "source": [
        "#CGAPoseNet = keras.models.load_model('weights.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8Cstcq9tTw9"
      },
      "outputs": [],
      "source": [
        "#prediction step\n",
        "y_pred = CGAPoseNet.predict(test_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtAVh4Xvz1B1"
      },
      "outputs": [],
      "source": [
        "#Storing the MSE between \\hat{M}, M over the test set\n",
        "\n",
        "MSE = []\n",
        "\n",
        "tot = 0\n",
        "cnt = 0\n",
        "for i in range(len(y_test)):\n",
        "    mse = (np.square(y_test[i] - y_pred[i])).mean()\n",
        "\n",
        "    MSE = np.append(MSE, mse)\n",
        "\n",
        "    #printing the first 20 motors M, \\hat{M} if the MSE between them is close\n",
        "    if cnt < 20 and mse < 0.0008:\n",
        "        print(\"original:\" , y_test[i])\n",
        "\n",
        "        X = y_test[i]\n",
        "        Y = y_pred[i]\n",
        "\n",
        "        M_real = X[0] + X[1]*e12 + X[2]*e13 + X[3]*e14 + X[4]*e23 + X[5]*e24 + X[6]*e34 + X[7]*e1234\n",
        "        M_pred = Y[0] + Y[1]*e12 + Y[2]*e13 + Y[3]*e14 + Y[4]*e23 + Y[5]*e24 + Y[6]*e34 + Y[7]*e1234\n",
        "\n",
        "        print(\"prediction:\", y_pred[i])\n",
        "        print(\"****\")\n",
        "        cnt += 1\n",
        "\n",
        "    tot += mse\n",
        "\n",
        "\n",
        "print(tot)\n",
        "np.save(\"MSE.npy\", MSE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzgy8beQvMtr"
      },
      "outputs": [],
      "source": [
        "#evaluating positional and rotational error\n",
        "\n",
        "origin = e4\n",
        "fig = plt.figure(figsize=(12, 12))\n",
        "ax = fig.add_subplot(projection='3d')\n",
        "list_of_lines = open(\"/content/drive/MyDrive/\"+ FOLDER + \"/dataset_test.txt\").readlines() # no need for closing, python will do it for you\n",
        "\n",
        "positional_error = []\n",
        "rotational_error = []\n",
        "\n",
        "translation = []\n",
        "translation_pred = []\n",
        "\n",
        "rotation = []\n",
        "rotation_pred = []\n",
        "for i in range(len(y_test)):\n",
        "    a = []\n",
        "    a = list_of_lines[i+3].split()\n",
        "\n",
        "    #x is required by the function down1D\n",
        "    x = float(a[1])*e1 + float(a[2])*e2 + float(a[3])*e3\n",
        "\n",
        "    X = y_test[i]\n",
        "    Y = y_pred[i]\n",
        "\n",
        "    #construct M and \\hat{M}\n",
        "    M_real = X[0] + X[1]*e12 + X[2]*e13 + X[3]*e14 + X[4]*e23 + X[5]*e24 + X[6]*e34 + X[7]*e1234\n",
        "    M_pred = Y[0] + Y[1]*e12 + Y[2]*e13 + Y[3]*e14 + Y[4]*e23 + Y[5]*e24 + Y[6]*e34 + Y[7]*e1234\n",
        "\n",
        "    #normalizing\n",
        "    M_pred = M_pred / sqrt((M_pred* ~M_pred)[0])\n",
        "\n",
        "    #predicted and real displacement vector \\hat{D}, D in spherical space\n",
        "    S = M_pred * origin * ~M_pred\n",
        "    T = M_real * origin * ~M_real\n",
        "\n",
        "    #predicted and real displacement vector \\hat{d}, d in Euclidean space\n",
        "    #s = down1D(S, x)\n",
        "    #t = down1D(T, x)\n",
        "\n",
        "    s = down1D(S)\n",
        "    t = down1D(T)\n",
        "\n",
        "    #POSITIONAL ERROR\n",
        "    mae = np.mean(np.abs(np.array([t[1], t[2], t[3]]) - np.array([s[1], s[2], s[3]])))\n",
        "\n",
        "    positional_error  = np.append(positional_error , mae)\n",
        "\n",
        "    translation = np.append(translation, np.array([t[1], t[2], t[3]]))\n",
        "    translation_pred = np.append(translation_pred, np.array([s[1], s[2], s[3]]))\n",
        "\n",
        "\n",
        "    #plotting the camera trace\n",
        "    ax.scatter(t[1], t[2], t[3], s = 20, c = \"r\")\n",
        "    ax.scatter(s[1], s[2], s[3], s = 20, c = \"b\", alpha = 0.5)\n",
        "\n",
        "    Tup = translation_rotor(t[1]*e1 + t[2]*e2 + t[3]*e3)\n",
        "    Sup = translation_rotor(s[1]*e1 + s[2]*e2 + s[3]*e3)\n",
        "\n",
        "    #predicted and real rotors \\hat{R}, R\n",
        "    R_pred = ~Sup* M_pred\n",
        "    R_real = ~Tup* M_real\n",
        "\n",
        "    if (R_real * ~R_pred)[0] > 1:\n",
        "        error = (np.arccos(1))*360/(2*np.pi)\n",
        "    elif (R_real * ~R_pred)[0] < -1:\n",
        "        error = (np.arccos(-1))*360/(2*np.pi)\n",
        "    else:\n",
        "        #ROTATIONAL ERROR\n",
        "        error = (np.arccos((R_real * ~R_pred)[0]))*360/(2*np.pi)\n",
        "\n",
        "    rotational_error = np.append(rotational_error, error)\n",
        "\n",
        "    rotation = np.append(rotation, np.array([R_real[0], R_real[6], R_real[7], R_real[10]]))\n",
        "    rotation_pred = np.append(rotation_pred, np.array([R_pred[0], R_pred[6], R_pred[7], R_pred[10]]))\n",
        "\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#storing rotational and translational errors\n",
        "np.save(\"translation_error.npy\", positional_error)\n",
        "np.save(\"rotational_error.npy\", rotational_error)\n",
        "\n",
        "#storing original and predicted translations\n",
        "np.save(\"T.npy\", translation)\n",
        "np.save(\"S.npy\", translation_pred)\n",
        "\n",
        "#storing original and predicted rotations\n",
        "np.save(\"R.npy\", rotation)\n",
        "np.save(\"Q.npy\", rotation_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dM7s2ENa6_Jd"
      },
      "outputs": [],
      "source": [
        "#plotting the camera orientation (coefficients e_{12}, e_{13}, e_{23} of rotor R)\n",
        "fig = plt.figure(figsize=(12, 12))\n",
        "ax = fig.add_subplot(projection='3d')\n",
        "\n",
        "N=200\n",
        "stride=1\n",
        "\n",
        "u = np.linspace(0, 2 * np.pi, N)\n",
        "v = np.linspace(0, np.pi, N)\n",
        "x = np.outer(np.cos(u), np.sin(v))\n",
        "y = np.outer(np.sin(u), np.sin(v))\n",
        "z = np.outer(np.ones(np.size(u)), np.cos(v))\n",
        "ax.plot_surface(x, y, z, linewidth=0.0, alpha = 0.1, cstride=stride, rstride=stride)\n",
        "\n",
        "ax.scatter(0, 0, 0, c = \"k\", marker = \"s\", label = \"O\")\n",
        "\n",
        "rotation = np.reshape(rotation, (-1, 4))\n",
        "rotation_pred = np.reshape(rotation_pred, (-1, 4))\n",
        "ax.scatter(rotation[:,1], rotation[:, 2], rotation[:,3], s = 15, c = \"r\")\n",
        "ax.scatter(rotation_pred[:,1], rotation_pred[:, 2], rotation_pred[:,3], s = 15, c = \"b\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8oUyqs82rlv"
      },
      "outputs": [],
      "source": [
        "print(np.median(positional_error))\n",
        "print(np.mean(  positional_error))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7waV5wh7vEVq"
      },
      "outputs": [],
      "source": [
        "print(np.median(rotational_error))\n",
        "print(np.mean(  rotational_error))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sV0bLkRJYirn"
      },
      "source": [
        "# Visualize Intermediate Outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8KJfpI_FFTM"
      },
      "outputs": [],
      "source": [
        "!pip uninstall kaleido"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-aCm6uVE8RJ"
      },
      "outputs": [],
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5pzA-HBPFCKc"
      },
      "outputs": [],
      "source": [
        "!conda install -c conda-forge python-kaleido"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnJRL_opYurA"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "example = next(test_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBEgGOZvM1AW"
      },
      "outputs": [],
      "source": [
        "for i in range(len(y_test)):\n",
        "    if np.allclose(y_test[i],example[1][0]):\n",
        "        IDX = i\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6Iu3OUn5rJp"
      },
      "outputs": [],
      "source": [
        "np.save(\"testimage.npy\", example[0][0])\n",
        "np.save(\"groundtruth.npy\", example[1][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02RwHD1H5gcc"
      },
      "outputs": [],
      "source": [
        "test = example[0][0]\n",
        "test = np.reshape(test, (-1, 224, 224, 3))\n",
        "CGAPoseNet.load_weights(\"weights.h5\")\n",
        "layer_outs = CGAPoseNet(test)\n",
        "print(layer_outs)\n",
        "np.save(\"predmotor.npy\", layer_outs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IuapXK-YkQG"
      },
      "outputs": [],
      "source": [
        "from keras import backend as K\n",
        "\n",
        "m = Model(inputs=CGAPoseNet.input, outputs=CGAPoseNet.layers[-4].output)\n",
        "layer4 = m(test)\n",
        "#np.save(\"64motors.npy\", layer4)\n",
        "\n",
        "m = Model(inputs=CGAPoseNet.input, outputs=CGAPoseNet.layers[-5].output)\n",
        "layer5 = m(test)\n",
        "#np.save(\"128motors.npy\", layer5)\n",
        "\n",
        "m = Model(inputs=CGAPoseNet.input, outputs=CGAPoseNet.layers[-6].output)\n",
        "layer6 = m(test)\n",
        "#np.save(\"256motors.npy\", layer6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pu1YYtFB6xfW"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "import plotly.io as pio\n",
        "import numpy as np\n",
        "\n",
        "x0 = np.multiply([0, 1, 2, 0], 10)\n",
        "y0 = np.multiply([0, 0, 1, 2], 10)\n",
        "z0 = np.multiply([0, 2, 0, 1], 10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HYu1FfSAl9I"
      },
      "outputs": [],
      "source": [
        "def packmotor(coeff):\n",
        "    N = 0\n",
        "    N += coeff[0]*1\n",
        "    N += coeff[1]*e12\n",
        "    N += coeff[2]*e13\n",
        "    N += coeff[3]*e14\n",
        "    N += coeff[4]*e23\n",
        "    N += coeff[5]*e24\n",
        "    N += coeff[6]*e34\n",
        "    N += coeff[7]*e1234\n",
        "\n",
        "    N = N  / sqrt((N* ~N)[0])\n",
        "    return N"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_BdaxiwDK4b"
      },
      "outputs": [],
      "source": [
        "M = packmotor(example[1][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjdRWPoLDR4H"
      },
      "outputs": [],
      "source": [
        "Mp = packmotor(np.array(layer_outs[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Nn-moGzBRWl"
      },
      "outputs": [],
      "source": [
        "x = float(position_test[IDX][0])*e1 + float(position_test[IDX][1])*e2 + float(position_test[IDX][2])*e3\n",
        "\n",
        "xr = []\n",
        "yr = []\n",
        "zr = []\n",
        "\n",
        "for i in range(len(x0)):\n",
        "    v = float(x0[i])*e1 + float(y0[i])*e2 + float(z0[i])*e3\n",
        "    V = up1D(v)\n",
        "    P = M * V * ~M\n",
        "\n",
        "    p = down1D(P)\n",
        "    xr.append(p[1])\n",
        "    yr.append(p[2])\n",
        "    zr.append(p[3])\n",
        "\n",
        "\n",
        "xp = []\n",
        "yp = []\n",
        "zp = []\n",
        "\n",
        "for i in range(len(x0)):\n",
        "    v = float(x0[i])*e1 + float(y0[i])*e2 + float(z0[i])*e3\n",
        "    V = up1D(v)\n",
        "    P = Mp * V * ~Mp\n",
        "\n",
        "    p = down1D(P)\n",
        "    xp.append(p[1])\n",
        "    yp.append(p[2])\n",
        "    zp.append(p[3])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hf65W2qgLnYG"
      },
      "outputs": [],
      "source": [
        "fig = go.Figure(data=[\n",
        "\n",
        "    go.Mesh3d(\n",
        "        x=xr,\n",
        "        y=yr,\n",
        "        z=zr,\n",
        "        #colorbar_title='z',\n",
        "        colorscale=[[0, 'firebrick'],\n",
        "                    [0.5, 'red'],\n",
        "                    [1, 'lightcoral']],\n",
        "        # Intensity of each vertex, which will be interpolated and color-coded\n",
        "        intensity = np.linspace(0, 1, 8, endpoint=True),\n",
        "        # i, j and k give the vertices of triangles\n",
        "        i=[0, 0, 0, 1],\n",
        "        j=[1, 2, 3, 2],\n",
        "        k=[2, 3, 1, 3],\n",
        "        showscale=False,\n",
        "        name = \"Ground Truth\"\n",
        "    ),\n",
        "\n",
        "    go.Mesh3d(\n",
        "        x=xp,\n",
        "        y=yp,\n",
        "        z=zp,\n",
        "        #colorbar_title='z',\n",
        "        colorscale=[[0, 'navy'],\n",
        "                    [0.5, 'blue'],\n",
        "                    [1, 'dodgerblue']],\n",
        "        # Intensity of each vertex, which will be interpolated and color-coded\n",
        "        intensity = np.linspace(0, 1, 8, endpoint=True),\n",
        "        # i, j and k give the vertices of triangles\n",
        "        i=[0, 0, 0, 1],\n",
        "        j=[1, 2, 3, 2],\n",
        "        k=[2, 3, 1, 3],\n",
        "        showscale=False,\n",
        "        name = \"Predicted\"\n",
        "\n",
        "    ),\n",
        "])\n",
        "fig.update_layout(plot_bgcolor='white', paper_bgcolor = 'rgba(0,0,0,0)', scene_aspectmode='data')\n",
        "pio.write_html(fig, file = \"tetrahedra.html\", auto_open = True)\n",
        "#pio.write_image(fig, file = \"tetrahedra_1.pdf\", scale=6, width=1080, height=1080)\n",
        "\n",
        "IPython.display.HTML(filename=\"tetrahedra.html\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UEkbNdObBG-"
      },
      "outputs": [],
      "source": [
        "\n",
        "M = 0\n",
        "for i in range(len(layer5[0])):\n",
        "    c = layer5[0][i]\n",
        "\n",
        "    xn = []\n",
        "    yn = []\n",
        "    zn = []\n",
        "\n",
        "    coeff = [float(c[0]), float(c[5]), float(c[6]),\n",
        "             float(c[7]), float(c[8]), float(c[9]),\n",
        "             float(c[10]), float(c[15])]\n",
        "\n",
        "    M += packmotor(coeff)\n",
        "\n",
        "\n",
        "M = M / len(layer5[0])\n",
        "M = M  / sqrt((M* ~M)[0])\n",
        "\n",
        "for j in range(len(x0)):\n",
        "    v = float(x0[j])*e1 + float(y0[j])*e2 + float(z0[j])*e3\n",
        "    V = up1D(v)\n",
        "    P = M * V * ~M\n",
        "    p = down1D(P)\n",
        "\n",
        "    xn.append(p[1])\n",
        "    yn.append(p[2])\n",
        "    zn.append(p[3])\n",
        "\n",
        "\n",
        "fig.add_trace(go.Mesh3d(\n",
        "    x=xn,\n",
        "    y=yn,\n",
        "    z=zn,\n",
        "        #colorbar_title='z',\n",
        "    colorscale=[[0, 'green'],\n",
        "                [0.5, 'limegreen'],\n",
        "                [1, 'lime']],\n",
        "    # Intensity of each vertex, which will be interpolated and color-coded\n",
        "    intensity = np.linspace(0, 1, 8, endpoint=True),\n",
        "    # i, j and k give the vertices of triangles\n",
        "    i=[0, 0, 0, 1],\n",
        "    j=[1, 2, 3, 2],\n",
        "    k=[2, 3, 1, 3],\n",
        "    showscale=False,\n",
        "    opacity = 0.5,\n",
        "    name = \"128 coeff\"\n",
        "))\n",
        "\n",
        "#pio.write_image(fig, file = \"tetrahedra_128.pdf\", scale=6, width=1080, height=1080)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKsxl7b7bIQp"
      },
      "outputs": [],
      "source": [
        "#fig3 = go.Figure()\n",
        "M = 0\n",
        "for i in range(len(layer6[0])):\n",
        "    c = layer6[0][i]\n",
        "\n",
        "    xn = []\n",
        "    yn = []\n",
        "    zn = []\n",
        "    coeff = [float(c[0]), float(c[5]), float(c[6]),\n",
        "             float(c[7]), float(c[8]), float(c[9]),\n",
        "             float(c[10]), float(c[15])]\n",
        "    M += packmotor(coeff)\n",
        "\n",
        "M = M / len(layer6[0])\n",
        "M = M  / sqrt((M* ~M)[0])\n",
        "\n",
        "for j in range(len(x0)):\n",
        "    v = float(x0[j])*e1 + float(y0[j])*e2 + float(z0[j])*e3\n",
        "    V = up1D(v)\n",
        "    P = M * V * ~M\n",
        "    p = down1D(P)\n",
        "\n",
        "    xn.append(p[1])\n",
        "    yn.append(p[2])\n",
        "    zn.append(p[3])\n",
        "\n",
        "\n",
        "fig.add_trace(go.Mesh3d(\n",
        "    x=xn,\n",
        "    y=yn,\n",
        "    z=zn,\n",
        "    #colorbar_title='z',\n",
        "    colorscale=[[0, 'orange'],\n",
        "                [0.5, 'gold'],\n",
        "                [1, 'yellow']],\n",
        "    # Intensity of each vertex, which will be interpolated and color-coded\n",
        "    intensity = np.linspace(0, 1, 8, endpoint=True),\n",
        "    # i, j and k give the vertices of triangles\n",
        "    i=[0, 0, 0, 1],\n",
        "    j=[1, 2, 3, 2],\n",
        "    k=[2, 3, 1, 3],\n",
        "    showscale=False,\n",
        "    opacity = 0.3,\n",
        "    name = \"256 coeff\"\n",
        "))\n",
        "\n",
        "#pio.write_image(fig3, file = \"tetrahedra_256.pdf\", scale=5, width=1080, height=1080)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tN7TGjN7y1lZ"
      },
      "outputs": [],
      "source": [
        "camera = dict(\n",
        "    eye=dict(x=-2, y=2, z=0.1)\n",
        ")\n",
        "\n",
        "\n",
        "fig.update_layout(scene_camera=camera)\n",
        "pio.write_html(fig, file = \"tetrahedra_all.html\", auto_open = True)\n",
        "IPython.display.HTML(filename=\"tetrahedra_all.html\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlmIwW14VYM-"
      },
      "outputs": [],
      "source": [
        "pio.write_html(fig, file = \"tetrahedra.html\", auto_open = True)\n",
        "#pio.write_image(fig, file = \"tetrahedra_all.pdf\", scale=5, width=1080, height=1080)\n",
        "IPython.display.HTML(filename=\"tetrahedra_all.html\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}