{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/albertomariapepe/CGA-PointNet/blob/main/CGA_PoseNet_(7_Scenes).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNmZCKUmcWM-"
      },
      "source": [
        "# Defining CGA-PoseNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQ1oXFXlt0-G"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, Reshape, MaxPooling2D, AveragePooling2D, Flatten, GlobalAveragePooling2D, Dense, Dropout\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Loading GoogLeNet with ImageNet weights\n",
        "\n",
        "from keras.applications.inception_v3 import InceptionV3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tupBY_l-i7F-"
      },
      "outputs": [],
      "source": [
        "!pip install tfga\n",
        "from tfga import GeometricAlgebra\n",
        "from tfga.layers import TensorToGeometric, GeometricProductConv1D, GeometricToTensor, GeometricSandwichProductDense, GeometricProductDense\n",
        "ga = GeometricAlgebra(metric=[1, 1, 1, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlXKY8-an-0h"
      },
      "outputs": [],
      "source": [
        "#modifying the last layer\n",
        "idx = ga.get_kind_blade_indices(\"even\")\n",
        "model = InceptionV3(classifier_activation = None, weights = \"imagenet\", input_tensor=Input(shape=(224, 224, 3)))\n",
        "\n",
        "x2 = Dropout(0.3)(model.layers[-2].output)\n",
        "x2 = Reshape((-1, 8))(x2)\n",
        "x2 = TensorToGeometric(ga, blade_indices=idx)(x2)\n",
        "x2 = GeometricSandwichProductDense(\n",
        "        ga, units=128, activation = \"relu\",\n",
        "        blade_indices_kernel=idx,\n",
        "        blade_indices_bias=idx)(x2)\n",
        "x2 = GeometricSandwichProductDense(\n",
        "        ga, units=64, activation = \"relu\",\n",
        "        blade_indices_kernel=idx,\n",
        "        blade_indices_bias=idx)(x2)\n",
        "x2 = GeometricSandwichProductDense(\n",
        "        ga, units=1, activation = \"tanh\",\n",
        "        blade_indices_kernel=idx,\n",
        "        blade_indices_bias=idx)(x2)\n",
        "x2 = GeometricToTensor(ga, blade_indices=idx)(x2)\n",
        "outputs2 = Flatten()(x2)\n",
        "\n",
        "\n",
        "Model1 = tf.keras.Model(inputs=model.input, outputs=outputs2)\n",
        "Model1.summary()\n",
        "CGAPoseNet = Model1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wCNz8twcZ9D"
      },
      "source": [
        "# Converting Camera Poses into Motors\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_59LfNqDLTD"
      },
      "outputs": [],
      "source": [
        "FOLDER = \"chess\" #Change the name to change the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlI5XNDYcbFj"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZG1xqTUIS7i"
      },
      "outputs": [],
      "source": [
        "!pip install clifford"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAzn_xo4omZv"
      },
      "outputs": [],
      "source": [
        "from clifford.g3c import *\n",
        "from math import sqrt\n",
        "\n",
        "lambda_coeff = 10\n",
        "\n",
        "#From Euclidean to 1D Up CGA.\n",
        "#function implementing Eq. 6 (convert a vector in Euclidean space into a rotor\n",
        "#in spherical space)\n",
        "def translation_rotor(a, L = lambda_coeff):\n",
        "    Ta = (L + a*e4)/(sqrt(L**2 + a**2))\n",
        "    return Ta\n",
        "\n",
        "#From Euclidean to 1D Up CGA. function implementing the Eq. 10 (X = f(x))\n",
        "def up1D(x, L = lambda_coeff):\n",
        "    Y = (2*L / (L**2 + x**2))*x + ((L**2-x**2)/(L**2 + x**2))*e4\n",
        "    return Y\n",
        "\n",
        "#From 1D Up CGA to Euclidean. function implementing the inverse of Eq. 10 (x = f^{-1}(X))\n",
        "def down1D(Y, x, L = lambda_coeff):\n",
        "    alpha = (2*L/(L**2 + x**2))\n",
        "    beta  =  (L**2 - x**2)/(L**2 + x**2)\n",
        "    x = (Y - beta*e4)/alpha\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1OMR-4NLaOmK"
      },
      "outputs": [],
      "source": [
        "#reads the dataset labels and converts them into motors (Train set)\n",
        "\n",
        "train = open(\"/content/drive/MyDrive/\"+ FOLDER + \"/TrainSplit.txt\").readlines()\n",
        "\n",
        "import os.path\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "import csv\n",
        "\n",
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "position_train = []\n",
        "\n",
        "dir = \"/content/drive/MyDrive/\"+ FOLDER + \"/\"\n",
        "\n",
        "with open(dir + 'TRAIN.csv', \"w\") as csv_file:\n",
        "    fieldnames = ['filename', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']\n",
        "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
        "    writer.writeheader()\n",
        "\n",
        "    #iterates over the number of video sequences\n",
        "    for i in range(len(train)):\n",
        "\n",
        "\n",
        "        print(i, \"/\", str(len(train)))\n",
        "\n",
        "        num = train[i][8]\n",
        "        files = os.listdir(\"/content/drive/MyDrive/\"+ FOLDER + \"/seq-0\" + str(num) +\"/\")\n",
        "        files.sort()\n",
        "\n",
        "\n",
        "        #iterates over every frame\n",
        "        for j in range(len(files)):\n",
        "            if j % 100 == 0:\n",
        "                print(\"  \", j, \"/\", str(len(files)))\n",
        "\n",
        "            #print(files[j])\n",
        "            if files[j].endswith('.pose.txt') and files[j].endswith('(1).pose.txt') == False:\n",
        "            #print(files[j])\n",
        "\n",
        "\n",
        "                with open(\"/content/drive/MyDrive/\"+ FOLDER + \"/seq-0\" + str(num) + \"/\" + files[j] , 'r') as f:\n",
        "                    l = [[float(num) for num in line.split('\\t ')] for line in f]\n",
        "\n",
        "      #converting the rotation matrix M into a rotor R\n",
        "                M = np.array(l)\n",
        "                B = [M[0,0]*e1 + M[1,0]*e2 + M[2,0]*e3,\n",
        "                    M[0,1]*e1 + M[1,1]*e2 + M[2,1]*e3,\n",
        "                    M[0,2]*e1 + M[1,2]*e2 + M[2,2]*e3]\n",
        "\n",
        "                A = [e1,e2,e3]\n",
        "                R = 1+sum([A[k]*B[k] for k in range(3)])\n",
        "                R = R/abs(R)\n",
        "\n",
        "                #mapping the position from Euclidean into spherical space\n",
        "                Ta = translation_rotor(float(M[0,3])*e1 + float(M[1,3])*e2 + float(M[2,3])*e3)\n",
        "                N = Ta*R\n",
        "\n",
        "\n",
        "                d = {'filename': \"seq-0\" + str(num) + \"/\" + files[j].split(\".\")[0] + \".color.png\",\n",
        "                     'a':N[0],\n",
        "                     'b':N[6],\n",
        "                     'c':N[7],\n",
        "                     'd':N[8],\n",
        "                     'e':N[10],\n",
        "                     'f':N[11],\n",
        "                     'g':N[13],\n",
        "                     'h':N[26]}\n",
        "                writer.writerow(d)\n",
        "\n",
        "\n",
        "#position_train = np.reshape(position_train, (-1, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLkC8FXs5rlm"
      },
      "outputs": [],
      "source": [
        "test = open(\"/content/drive/MyDrive/\"+ FOLDER + \"/TestSplit.txt\").readlines()\n",
        "\n",
        "y_test = []\n",
        "position_test = []\n",
        "\n",
        "#iterates over the number of video sequences\n",
        "with open(dir + 'TEST.csv', \"w\") as csv_file:\n",
        "    fieldnames = ['filename', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']\n",
        "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
        "    writer.writeheader()\n",
        "\n",
        "    #iterates over the number of video sequences\n",
        "    for i in range(len(test)):\n",
        "\n",
        "\n",
        "        print(i, \"/\", str(len(test)))\n",
        "\n",
        "        num = test[i][8]\n",
        "        files = os.listdir(\"/content/drive/MyDrive/\"+ FOLDER + \"/seq-0\" + str(num) +\"/\")\n",
        "        files.sort()\n",
        "\n",
        "\n",
        "        #iterates over every frame\n",
        "        for j in range(len(files)):\n",
        "            if j % 100 == 0:\n",
        "                print(\"  \", j, \"/\", str(len(files)))\n",
        "\n",
        "            #print(files[j])\n",
        "            if files[j].endswith('.pose.txt') and files[j].endswith('(1).pose.txt') == False:\n",
        "            #print(files[j])\n",
        "\n",
        "\n",
        "                with open(\"/content/drive/MyDrive/\"+ FOLDER + \"/seq-0\" + str(num) + \"/\" + files[j] , 'r') as f:\n",
        "                    l = [[float(num) for num in line.split('\\t ')] for line in f]\n",
        "\n",
        "      #converting the rotation matrix M into a rotor R\n",
        "                M = np.array(l)\n",
        "                B = [M[0,0]*e1 + M[1,0]*e2 + M[2,0]*e3,\n",
        "                    M[0,1]*e1 + M[1,1]*e2 + M[2,1]*e3,\n",
        "                    M[0,2]*e1 + M[1,2]*e2 + M[2,2]*e3]\n",
        "\n",
        "                A = [e1,e2,e3]\n",
        "                R = 1+sum([A[k]*B[k] for k in range(3)])\n",
        "                R = R/abs(R)\n",
        "\n",
        "                #mapping the position from Euclidean into spherical space\n",
        "                Ta = translation_rotor(float(M[0,3])*e1 + float(M[1,3])*e2 + float(M[2,3])*e3)\n",
        "                N = Ta*R\n",
        "\n",
        "                y_test = np.append(y_test, [N[0], N[6], N[7], N[8], N[10], N[11], N[13], N[26]])\n",
        "                position_test = np.append(position_test, [M[0,3], M[1,3], M[2,3]])\n",
        "\n",
        "\n",
        "                d = {'filename': \"seq-0\" + str(num) + \"/\" + files[j].split(\".\")[0] + \".color.png\",\n",
        "                     'a':N[0],\n",
        "                     'b':N[6],\n",
        "                     'c':N[7],\n",
        "                     'd':N[8],\n",
        "                     'e':N[10],\n",
        "                     'f':N[11],\n",
        "                     'g':N[13],\n",
        "                     'h':N[26]}\n",
        "                writer.writerow(d)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhx8pLt50nTD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_train =pd.read_csv(dir + '/TRAIN.csv')\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        validation_split=0.2)\n",
        "\n",
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        rescale=1./255)\n",
        "\n",
        "'''\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        'drive/MyDrive/300W-LP/',\n",
        "        target_size=(img_shape, img_shape),\n",
        "        batch_size=batch_size,\n",
        "        shuffle = True,\n",
        "        class_mode=None)\n",
        "'''\n",
        "\n",
        "#df = pd.read_csv(dir + 'train_df.csv', delimiter=' ', header=None, names=['filename', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'])\n",
        "columns = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']\n",
        "train_generator = train_datagen.flow_from_dataframe(dataframe=df_train, directory=dir,\n",
        "                                              x_col=\"filename\", y_col=columns, has_ext=True,\n",
        "                                              class_mode=\"raw\", target_size=(224, 224),\n",
        "                                              shuffle = True,\n",
        "                                              subset=\"training\",\n",
        "                                              sort = False,\n",
        "                                              batch_size=64)\n",
        "\n",
        "val_generator = train_datagen.flow_from_dataframe(dataframe=df_train, directory=dir,\n",
        "                                              x_col=\"filename\", y_col=columns, has_ext=True,\n",
        "                                              class_mode=\"raw\", target_size=(224, 224),\n",
        "                                              shuffle = True,\n",
        "                                              subset=\"validation\",\n",
        "                                              sort = False,\n",
        "                                              batch_size=64)\n",
        "\n",
        "df_test =pd.read_csv(dir + '/TEST.csv')\n",
        "test_generator = test_datagen.flow_from_dataframe(dataframe=df_test, directory=dir,\n",
        "                                              x_col=\"filename\", y_col=columns, has_ext=True,\n",
        "                                              class_mode=\"raw\", target_size=(224, 224),\n",
        "                                              shuffle = False,\n",
        "                                              sort = False,\n",
        "                                              batch_size=64)\n",
        "\n",
        "y_test = np.reshape(y_test, (-1, 8))\n",
        "position_test = np.reshape(position_test, (-1, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf7ghzupKIjZ"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ue9UxWZ5r1-m"
      },
      "outputs": [],
      "source": [
        "#defining hyperparameters\n",
        "\n",
        "nb_epoch = 100\n",
        "batch_size = 64\n",
        "initial_learning_rate = 1e-4\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.98,\n",
        "    staircase=True)\n",
        "\n",
        "#compiling the model\n",
        "CGAPoseNet.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
        "                 loss=\"mse\", run_eagerly=True)\n",
        "\n",
        "es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=12, restore_best_weights = True)\n",
        "\n",
        "#training\n",
        "model_train = CGAPoseNet.fit(train_generator,\n",
        "                            validation_data=val_generator,\n",
        "                            epochs=nb_epoch,\n",
        "                            verbose=1,\n",
        "                            shuffle=True,\n",
        "                            callbacks = es_callback,\n",
        "                            batch_size=batch_size)\n",
        "\n",
        "#plotting losses\n",
        "loss = model_train.history['loss']\n",
        "val_loss = model_train.history['val_loss']\n",
        "epochs = range(0,np.size(loss))\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'b-', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r-', label='Validation loss')\n",
        "plt.title('Training loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "by0gFJhDS3TL"
      },
      "outputs": [],
      "source": [
        "#storing losses\n",
        "np.save(\"NB_train_loss.npy\", loss)\n",
        "np.save(\"NB_val_loss.npy\", val_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z245LMHDTFn-"
      },
      "outputs": [],
      "source": [
        "#saving weights\n",
        "CGAPoseNet.save('weights.h5')\n",
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSwIlA-Rv96v"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCX25ZCxq8IY"
      },
      "outputs": [],
      "source": [
        "GAPoseNet = keras.models.load_model('weights.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8Cstcq9tTw9"
      },
      "outputs": [],
      "source": [
        "#prediction step\n",
        "y_pred = CGAPoseNet.predict(test_generator)\n",
        "#np.save(\"y_pred.npy\", y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#Storing the MSE between \\hat{M}, M over the test set\n",
        "\n",
        "MSE = []\n",
        "\n",
        "tot = 0\n",
        "cnt = 0\n",
        "for i in range(len(y_test)):\n",
        "    mse = (np.square(y_test[i] - y_pred[i])).mean()\n",
        "\n",
        "    MSE = np.append(MSE, mse)\n",
        "\n",
        "    #printing the first 20 motors M, \\hat{M} if the MSE between them is close\n",
        "    if cnt < 20 and mse < 0.0008:\n",
        "        print(\"original:\" , y_test)\n",
        "\n",
        "        X = y_test[i]\n",
        "        Y = y_pred[i]\n",
        "\n",
        "        M_real = X[0] + X[1]*e12 + X[2]*e13 + X[3]*e14 + X[4]*e23 + X[5]*e24 + X[6]*e34 + X[7]*e1234\n",
        "        M_pred = Y[0] + Y[1]*e12 + Y[2]*e13 + Y[3]*e14 + Y[4]*e23 + Y[5]*e24 + Y[6]*e34 + Y[7]*e1234\n",
        "\n",
        "        print(\"prediction:\", y_pred[i])\n",
        "        print(\"****\")\n",
        "        cnt += 1\n",
        "\n",
        "    tot += mse\n",
        "\n",
        "\n",
        "print(tot)\n",
        "np.save(\"MSE.npy\", MSE)"
      ],
      "metadata": {
        "id": "2YMEcdLkROtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "origin = e4\n",
        "fig = plt.figure(figsize=(12, 12))\n",
        "ax = fig.add_subplot(projection='3d')\n",
        "#list_of_lines = open(\"/content/drive/MyDrive/\"+ FOLDER + \"/dataset_test.txt\").readlines() # no need for closing, python will do it for you\n",
        "\n",
        "positional_error = []\n",
        "rotational_error = []\n",
        "\n",
        "translation = []\n",
        "translation_pred = []\n",
        "\n",
        "rotation = []\n",
        "rotation_pred = []\n",
        "\n",
        "position = position_test\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "    #a = []\n",
        "    #a = list_of_lines[i+3].split()\n",
        "\n",
        "    #print(a)\n",
        "\n",
        "    #x = float(a[1])*e1 + float(a[2])*e2 + float(a[3])*e3\n",
        "    x = position[i,0]*e1 + position[i,1]*e2 + position[i,2]*e3\n",
        "\n",
        "    X = y_test[i]\n",
        "    Y = y_pred[i]\n",
        "\n",
        "    #construct M and \\hat{M}\n",
        "    M_real = X[0] + X[1]*e12 + X[2]*e13 + X[3]*e14 + X[4]*e23 + X[5]*e24 + X[6]*e34 + X[7]*e1234\n",
        "    M_pred = Y[0] + Y[1]*e12 + Y[2]*e13 + Y[3]*e14 + Y[4]*e23 + Y[5]*e24 + Y[6]*e34 + Y[7]*e1234\n",
        "\n",
        "    #normalizing\n",
        "    M_pred = M_pred / sqrt((M_pred* ~M_pred)[0])\n",
        "\n",
        "    #predicted and real displacement vector \\hat{D}, D in spherical space\n",
        "    S = M_pred * origin * ~M_pred\n",
        "    T = M_real * origin * ~M_real\n",
        "\n",
        "    #predicted and real displacement vector \\hat{d}, d in Euclidean space\n",
        "    s = down1D(S, x)\n",
        "    t = down1D(T, x)\n",
        "\n",
        "    #POSITIONAL ERROR\n",
        "    mae = np.mean(np.abs(np.array([t[1], t[2], t[3]]) - np.array([s[1], s[2], s[3]])))\n",
        "\n",
        "    positional_error  = np.append(positional_error , mae)\n",
        "\n",
        "    translation = np.append(translation, np.array([t[1], t[2], t[3]]))\n",
        "    translation_pred = np.append(translation_pred, np.array([s[1], s[2], s[3]]))\n",
        "\n",
        "\n",
        "    #plotting the camera trace\n",
        "    ax.scatter(t[1], t[2], t[3], s = 20, c = \"r\")\n",
        "    ax.scatter(s[1], s[2], s[3], s = 20, c = \"b\", alpha = 0.5)\n",
        "\n",
        "    Tup = translation_rotor(t[1]*e1 + t[2]*e2 + t[3]*e3)\n",
        "    Sup = translation_rotor(s[1]*e1 + s[2]*e2 + s[3]*e3)\n",
        "\n",
        "    #predicted and real rotors \\hat{R}, R\n",
        "    R_pred = ~Sup* M_pred\n",
        "    R_real = ~Tup* M_real\n",
        "\n",
        "    if (R_real * ~R_pred)[0] > 1:\n",
        "        error = (np.arccos(1))*360/(2*np.pi)\n",
        "    elif (R_real * ~R_pred)[0] < -1:\n",
        "        error = (np.arccos(-1))*360/(2*np.pi)\n",
        "    else:\n",
        "        #ROTATIONAL ERROR\n",
        "        error = (np.arccos((R_real * ~R_pred)[0]))*360/(2*np.pi)\n",
        "\n",
        "    rotational_error = np.append(rotational_error, error)\n",
        "\n",
        "    rotation = np.append(rotation, np.array([R_real[0], R_real[6], R_real[7], R_real[10]]))\n",
        "    rotation_pred = np.append(rotation_pred, np.array([R_pred[0], R_pred[6], R_pred[7], R_pred[10]]))\n",
        "\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#storing rotational and translational errors\n",
        "np.save(\"translation_error.npy\", positional_error)\n",
        "np.save(\"rotational_error.npy\", rotational_error)\n",
        "\n",
        "#storing original and predicted translations\n",
        "np.save(\"T.npy\", translation)\n",
        "np.save(\"S.npy\", translation_pred)\n",
        "\n",
        "#storing original and predicted rotations\n",
        "np.save(\"R.npy\", rotation)\n",
        "np.save(\"Q.npy\", rotation_pred)"
      ],
      "metadata": {
        "id": "Rvh5wkVMx9pv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "origin = e4\n",
        "fig = plt.figure(figsize=(12, 12))\n",
        "ax = fig.add_subplot(projection='3d')\n",
        "#list_of_lines = open(\"/content/drive/MyDrive/\"+ FOLDER + \"/dataset_test.txt\").readlines() # no need for closing, python will do it for you\n",
        "\n",
        "positional_error = []\n",
        "rotational_error = []\n",
        "\n",
        "translation = []\n",
        "translation_pred = []\n",
        "\n",
        "rotation = []\n",
        "rotation_pred = []\n",
        "\n",
        "position = position_test\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "    #a = []\n",
        "    #a = list_of_lines[i+3].split()\n",
        "\n",
        "    #print(a)\n",
        "\n",
        "    #x = float(a[1])*e1 + float(a[2])*e2 + float(a[3])*e3\n",
        "    x = position[i,0]*e1 + position[i,1]*e2 + position[i,2]*e3\n",
        "\n",
        "    X = y_test[i]\n",
        "    Y = y_pred[i]\n",
        "\n",
        "    #construct M and \\hat{M}\n",
        "    M_real = X[0] + X[1]*e12 + X[2]*e13 + X[3]*e14 + X[4]*e23 + X[5]*e24 + X[6]*e34 + X[7]*e1234\n",
        "    M_pred = Y[0] + Y[1]*e12 + Y[2]*e13 + Y[3]*e14 + Y[4]*e23 + Y[5]*e24 + Y[6]*e34 + Y[7]*e1234\n",
        "\n",
        "    #normalizing\n",
        "    M_pred = M_pred / sqrt((M_pred* ~M_pred)[0])\n",
        "\n",
        "    #predicted and real displacement vector \\hat{D}, D in spherical space\n",
        "    S = M_pred * origin * ~M_pred\n",
        "    T = M_real * origin * ~M_real\n",
        "\n",
        "    #predicted and real displacement vector \\hat{d}, d in Euclidean space\n",
        "    s = down1D(S, x)\n",
        "    t = down1D(T, x)\n",
        "\n",
        "    #POSITIONAL ERROR\n",
        "    mae = np.mean(np.abs(np.array([t[1], t[2], t[3]]) - np.array([s[1], s[2], s[3]])))\n",
        "\n",
        "    positional_error  = np.append(positional_error , mae)\n",
        "\n",
        "    translation = np.append(translation, np.array([t[1], t[2], t[3]]))\n",
        "    translation_pred = np.append(translation_pred, np.array([s[1], s[2], s[3]]))\n",
        "\n",
        "\n",
        "    #plotting the camera trace\n",
        "    ax.scatter(t[1], t[2], t[3], s = 20, c = \"r\")\n",
        "    ax.scatter(s[1], s[2], s[3], s = 20, c = \"b\", alpha = 0.5)\n",
        "\n",
        "    Tup = translation_rotor(t[1]*e1 + t[2]*e2 + t[3]*e3)\n",
        "    Sup = translation_rotor(s[1]*e1 + s[2]*e2 + s[3]*e3)\n",
        "\n",
        "    #predicted and real rotors \\hat{R}, R\n",
        "    R_pred = ~Sup* M_pred\n",
        "    R_real = ~Tup* M_real\n",
        "\n",
        "    if (R_real * ~R_pred)[0] > 1:\n",
        "        error = (np.arccos(1))*360/(2*np.pi)\n",
        "    elif (R_real * ~R_pred)[0] < -1:\n",
        "        error = (np.arccos(-1))*360/(2*np.pi)\n",
        "    else:\n",
        "        #ROTATIONAL ERROR\n",
        "        error = (np.arccos((R_real * ~R_pred)[0]))*360/(2*np.pi)\n",
        "\n",
        "    rotational_error = np.append(rotational_error, error)\n",
        "\n",
        "    rotation = np.append(rotation, np.array([R_real[0], R_real[6], R_real[7], R_real[10]]))\n",
        "    rotation_pred = np.append(rotation_pred, np.array([R_pred[0], R_pred[6], R_pred[7], R_pred[10]]))\n",
        "\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#storing rotational and translational errors\n",
        "np.save(\"translation_error.npy\", positional_error)\n",
        "np.save(\"rotational_error.npy\", rotational_error)\n",
        "\n",
        "#storing original and predicted translations\n",
        "np.save(\"T.npy\", translation)\n",
        "np.save(\"S.npy\", translation_pred)\n",
        "\n",
        "#storing original and predicted rotations\n",
        "np.save(\"R.npy\", rotation)\n",
        "np.save(\"Q.npy\", rotation_pred)"
      ],
      "metadata": {
        "id": "fsKI3MM0RSte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting the camera orientation (coefficients e_{12}, e_{13}, e_{23} of rotor R)\n",
        "fig = plt.figure(figsize=(12, 12))\n",
        "ax = fig.add_subplot(projection='3d')\n",
        "\n",
        "N=200\n",
        "stride=1\n",
        "\n",
        "u = np.linspace(0, 2 * np.pi, N)\n",
        "v = np.linspace(0, np.pi, N)\n",
        "x = np.outer(np.cos(u), np.sin(v))\n",
        "y = np.outer(np.sin(u), np.sin(v))\n",
        "z = np.outer(np.ones(np.size(u)), np.cos(v))\n",
        "ax.plot_surface(x, y, z, linewidth=0.0, alpha = 0.1, cstride=stride, rstride=stride)\n",
        "\n",
        "ax.scatter(0, 0, 0, c = \"k\", marker = \"s\", label = \"O\")\n",
        "\n",
        "rotation = np.reshape(rotation, (-1, 4))\n",
        "rotation_pred = np.reshape(rotation_pred, (-1, 4))\n",
        "ax.scatter(rotation[:,1], rotation[:, 2], rotation[:,3], s = 15, c = \"r\")\n",
        "ax.scatter(rotation_pred[:,1], rotation_pred[:, 2], rotation_pred[:,3], s = 15, c = \"b\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XfGPLct3yAUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.median(positional_error))\n",
        "print(np.mean(  positional_error))"
      ],
      "metadata": {
        "id": "UCn9N7YQRcEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYMZoh-t2tB4"
      },
      "outputs": [],
      "source": [
        "print(np.median(rotational_error))\n",
        "print(np.mean(  rotational_error))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}